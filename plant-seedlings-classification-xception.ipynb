{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'train', 'test']\n",
      "['Common Chickweed', 'Fat Hen', 'Loose Silky-bent', 'Small-flowered Cranesbill', 'Shepherds Purse', 'Maize', 'Sugar beet', 'Common wheat', 'Cleavers', 'Black-grass', 'Charlock', 'Scentless Mayweed']\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Dropout,GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from keras.applications import Xception\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "h=299\n",
    "w=299\n",
    "h_predict=299\n",
    "w_predict=299\n",
    "bs=16\n",
    "E=100\n",
    "\n",
    "name_dic = {'Black-grass': 0, 'Charlock': 1, 'Cleavers': 2, 'Common Chickweed': 3, 'Common wheat': 4,\n",
    "                'Fat Hen': 5, 'Loose Silky-bent': 6, 'Maize': 7, 'Scentless Mayweed': 8, 'Shepherds Purse': 9,\n",
    "                'Small-flowered Cranesbill': 10, 'Sugar beet': 11}\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/train\"))\n",
    "name_dic2 = {'0': 'Black-grass', '1': 'Charlock', '2': 'Cleavers',\n",
    "                '3': 'Common Chickweed', '4': 'Common wheat',\n",
    "                '5': 'Fat Hen', '6': 'Loose Silky-bent', '7': 'Maize',\n",
    "                '8': 'Scentless Mayweed', '9': 'Shepherds Purse',\n",
    "                '10': 'Small-flowered Cranesbill', '11': 'Sugar beet'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_for_plant(image):\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    sensitivity = 35\n",
    "    lower_hsv = np.array([60 - sensitivity, 100, 50])\n",
    "    upper_hsv = np.array([60 + sensitivity, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def segment_plant(image):\n",
    "    mask = create_mask_for_plant(image)\n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return output\n",
    "\n",
    "def sharpen_image(image):\n",
    "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
    "    return image_sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(path):\n",
    "    images=[]   #存的是np数组的照片\n",
    "    labels=[]   #存的是照片对应的one hot label\n",
    "    for file_name in os.listdir(path):\n",
    "        for img_name in os.listdir(path+file_name):\n",
    "            image=cv2.imread(path+file_name+r'/'+img_name)\n",
    "            #if image is not None:\n",
    "            #image = segment_plant(image)\n",
    "            #image = sharpen_image(image)\n",
    "            image=cv2.resize(image,(h,w))       #?????\n",
    "            images.append(image)#(path+file_name+r'/'+img_name)\n",
    "            labels.append(int(name_dic[file_name]))\n",
    "    images=np.reshape(images,(-1,h,w,3))#.astype(np.float32)/255.0\n",
    "    labels=np.array(labels)\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img_predict(path):\n",
    "    images=[]   #存的是np数组的照片\n",
    "    labels_name=[]   #存的是照片对应的one hot label\n",
    "    for file_name in os.listdir(path):\n",
    "        #for img_name in os.listdir(path+file_name):\n",
    "        image=cv2.imread(path+file_name)\n",
    "        #if image is not None:\n",
    "        #image = segment_plant(image)\n",
    "        #image = sharpen_image(image)\n",
    "        image=cv2.resize(image,(h_predict,w_predict))       #?????\n",
    "        images.append(image)#(path+file_name+r'/'+img_name)\n",
    "        labels_name.append(file_name)\n",
    "    images=np.reshape(images,(-1,h_predict,w_predict,3))#.astype(np.float32)/255.0\n",
    "    #labels_name=np.array(labels)  #不需要，后面需要是一个list\n",
    "    return images,labels_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels=preprocess_img('../input/train/')  #之前报错，是因为除以两次255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_predict,labels_name=preprocess_img_predict('../input/test/')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_test, label_train, label_test = train_test_split(images, labels, test_size=0.2, shuffle=True)\n",
    "#shuffle默认true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train_onehot = to_categorical(label_train, 12)\n",
    "label_test_onehot = to_categorical(label_test, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del labels\n",
    "del images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(a,b):\n",
    "    benchmark=Xception(weights='imagenet',input_shape=(a,b,3),include_top=False)\n",
    "    x=benchmark.output\n",
    "    #print(x.shape)\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(1024,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model=Model(inputs=benchmark.input,outputs=x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(H):\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    #N = E # 训练周期数\n",
    "    N=len(H.epoch)\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('plot.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "train_generator=train_datagen.flow(img_train,label_train_onehot,batch_size=bs)\n",
    "\n",
    "#train_test_generator=train_datagen.flow(images,labels_onehot,batch_size=bs)\n",
    "\n",
    "#filepath='../input/weights.best_{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "rlr=ReduceLROnPlateau(monitor='val_acc',patience=3,factor=0.4,min_lr=0.00001,verbose=1)\n",
    "#es=EarlyStopping(monitor='val_acc',patience=5)\n",
    "#es=\n",
    "#ckp=ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True)\n",
    "callbacks_list=[rlr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test():\n",
    "    model=get_model(h,w)\n",
    "    model.compile(optimizer='Adadelta',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    H=model.fit_generator(train_generator,steps_per_epoch=img_train.shape[0]//bs,epochs=E,validation_data=(img_test,label_test_onehot),callbacks=callbacks_list)   #len(img_train)//bs\n",
    "    #img_predict=model.predict(img_test)\n",
    "    #os.mkdir('model.h5')\n",
    "    #model.save_weights('model.h5')\n",
    "    #print('succeed save')\n",
    "    #print(os.listdir(\"../input\"))\n",
    "    img_predict = model.predict(img_test)\n",
    "    img_predict_onehot=np.argmax(img_predict,axis=1)\n",
    "\n",
    "    matrix = pd.crosstab(label_test, img_predict_onehot, rownames=['label'], colnames=['predict'])\n",
    "    print(matrix)\n",
    "\n",
    "    show_train_history(H)\n",
    "    #print('firt done')\n",
    "    \n",
    "    #HH=model.fit(img_test,label_test_onehot,epochs=3,batch_size=bs)\n",
    "    model.save_weights('model.h5')\n",
    "    #show_train_history(H)\n",
    "    #print('succeed save')\n",
    "    #print('second done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 6s 0us/step\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "237/237 [==============================] - 116s 490ms/step - loss: 0.9866 - acc: 0.6857 - val_loss: 0.4519 - val_acc: 0.8863\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 0.4287 - acc: 0.8668 - val_loss: 0.5285 - val_acc: 0.8747\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 0.3308 - acc: 0.8945 - val_loss: 0.2390 - val_acc: 0.9326\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 0.2841 - acc: 0.9082 - val_loss: 0.2818 - val_acc: 0.9274\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 0.2620 - acc: 0.9122 - val_loss: 0.2927 - val_acc: 0.9084\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 0.2270 - acc: 0.9280 - val_loss: 0.3680 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.4.\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 103s 433ms/step - loss: 0.1382 - acc: 0.9525 - val_loss: 0.1113 - val_acc: 0.9674\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 0.1214 - acc: 0.9575 - val_loss: 0.1111 - val_acc: 0.9653\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 103s 433ms/step - loss: 0.1045 - acc: 0.9673 - val_loss: 0.1014 - val_acc: 0.9716\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 0.1179 - acc: 0.9655 - val_loss: 0.1181 - val_acc: 0.9642\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 0.1044 - acc: 0.9678 - val_loss: 0.1111 - val_acc: 0.9642\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 0.0912 - acc: 0.9668 - val_loss: 0.1046 - val_acc: 0.9737\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 0.0903 - acc: 0.9715 - val_loss: 0.1162 - val_acc: 0.9674\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 0.0827 - acc: 0.9718 - val_loss: 0.1099 - val_acc: 0.9726\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 103s 433ms/step - loss: 0.0776 - acc: 0.9742 - val_loss: 0.1149 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.1600000023841858.\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 103s 433ms/step - loss: 0.0698 - acc: 0.9765 - val_loss: 0.0994 - val_acc: 0.9695\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 103s 433ms/step - loss: 0.0561 - acc: 0.9815 - val_loss: 0.1288 - val_acc: 0.9642\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 0.0478 - acc: 0.9855 - val_loss: 0.1036 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.06399999856948853.\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 0.0383 - acc: 0.9868 - val_loss: 0.0964 - val_acc: 0.9789\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 0.0474 - acc: 0.9842 - val_loss: 0.0993 - val_acc: 0.9726\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 102s 431ms/step - loss: 0.0431 - acc: 0.9855 - val_loss: 0.1000 - val_acc: 0.9726\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 102s 431ms/step - loss: 0.0411 - acc: 0.9866 - val_loss: 0.1043 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.025599998235702515.\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 102s 431ms/step - loss: 0.0490 - acc: 0.9847 - val_loss: 0.0971 - val_acc: 0.9726\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 0.0364 - acc: 0.9871 - val_loss: 0.0948 - val_acc: 0.9758\n",
      "Epoch 25/100\n",
      "172/237 [====================>.........] - ETA: 26s - loss: 0.0387 - acc: 0.9855"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    train_test()\n",
    "    #print('train finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load succeed\n"
     ]
    }
   ],
   "source": [
    "def predict():\n",
    "    model=get_model(h_predict,w_predict)   #h_predict,w_predict\n",
    "    model.load_weights('model.h5')\n",
    "    print('load succeed')\n",
    "    p=model.predict(images_predict)\n",
    "    p_onehot=np.argmax(p,axis=1)\n",
    "    \n",
    "    list=[]\n",
    "    for i in p_onehot:\n",
    "        list.append(name_dic2[str(i)])\n",
    "    #print(len(label_name))\n",
    "    #print(len(list))\n",
    "    result=pd.DataFrame({'file':labels_name,'species':list})\n",
    "    result.to_csv('myresult_noseg.csv',index=False)\n",
    "    #print('finish')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    predict()   \n",
    "    #print('predict finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
